{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from ucimlrepo import fetch_ucirepo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Algorithm 1 DTEC algorithm\n",
    "# Require: Dataset X, number of clusters K (not obligatory).\n",
    "# Ensure: An unsupervised evidential decision tree T.\n",
    "# Initialize the root node of decision tree T using dataset X;\n",
    "# while there is unevaluated node of single cluster do\n",
    "# Evaluate all possible cutting points at the taken node by the evidential silhouette metric using Eqs. (4)-(7);\n",
    "# Select the cutting point with the largest average silhouette value;\n",
    "# if the average silhouette value after splitting is larger than before then\n",
    "# Split this node of single cluster using Eqs. (8)-(10);\n",
    "# Determine the boundaries of the generated child nodes;\n",
    "# Use these boundaries to split the node of meta-cluster which includes the above single cluster;\n",
    "# else\n",
    "# Go to next node;\n",
    "# end if\n",
    "# end while\n",
    "# while K is available and the number of generated clusters is not equal to K do\n",
    "# if the number of generated clusters is larger than K then\n",
    "# Evaluate the quality of each single cluster by the evidential silhouette metric using Eq. (11);\n",
    "# Merge the cluster having lowest quality with its nearest cluster;\n",
    "# else\n",
    "# Continue splitting at the leaf node that has the largest average evidential silhouette value after splitting.\n",
    "# end if\n",
    "# end while"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class DecisionNode:\n",
    "    \"\"\"Class to represent a decision node in a decision tree.\"\"\"\n",
    "    \n",
    "    def __init__(self, left, right, mass_functions, decision_function, instance_indices, class_label=None):\n",
    "        \"\"\"Create a node with a left child, right child, decision function and optional class label.\n",
    "        This is a binary tree so each node has two children (left and right). \n",
    "        The decision function is used to make a decision when the node is asked to classify an instance.\n",
    "        \n",
    "        Args:\n",
    "            left (DecisionNode) : left child node\n",
    "            right (DecisionNode) : right child node\n",
    "            decision_function (function) : function to make decision\n",
    "            class_label (int) : optional class label for the node\n",
    "        \"\"\"\n",
    "        self.left = left\n",
    "        self.right = right\n",
    "        self.mass_functions = mass_functions\n",
    "        self.instance_indices = instance_indices\n",
    "        self.decision_function = decision_function\n",
    "        self.class_label = class_label\n",
    "        \n",
    "    def decide(self, feature):\n",
    "        \"\"\"Classify an instance based on its feature vector using the decision function.\"\"\"\n",
    "        if self.class_label is not None:\n",
    "            return self.class_label\n",
    "        elif self.decision_function(feature):\n",
    "            return self.left.decide(feature)\n",
    "        else:\n",
    "            return self.right.decide(feature)\n",
    "        \n",
    "\n",
    "# Pignistic probability BetP(A) = summation(|A âˆ© B|/|B|) . m(B) \n",
    "# where A is a subset of B, and m(B) is the mass function of B.\n",
    "# The pignistic probability is a measure of the belief in the proposition A given the evidence B.\n",
    "class DecisonTree:\n",
    "    \"\"\"Class to represent a decision tree model for classification.\"\"\"\n",
    "    \n",
    "    def __init__(self, max_depth=None):\n",
    "        \"\"\"Create a decision tree model.\n",
    "        \n",
    "        Args:\n",
    "            max_depth (int) : maximum depth of the tree\n",
    "        \"\"\"\n",
    "        self.max_depth = max_depth\n",
    "        self.Dataset = fetch_ucirepo(id=109)\n",
    "        self.X = self.Dataset.data.features\n",
    "        #convert X to a numpy array\n",
    "        self.X = np.array(self.X)\n",
    "        self.y = self.Dataset.data.targets\n",
    "        #convert y to a numpy array\n",
    "        self.y = np.array(self.y)\n",
    "        self.mass_functions = {}\n",
    "        self.metadata = self.Dataset.metadata\n",
    "        self.variables = self.Dataset.variables\n",
    "        self.root_instance_indices = np.arange(len(self.X))\n",
    "        self.root = None  \n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        \"\"\"Build the decision tree model by fitting to the data.\n",
    "        \n",
    "        Args:\n",
    "            X (array-like) : feature vectors\n",
    "            y (array-like) : class labels\n",
    "        \"\"\"\n",
    "        self.root = self._build_tree(X, y, depth=0)\n",
    "        \n",
    "    def _build_tree(self, X, y, depth):\n",
    "        \"\"\"Recursively build the decision tree model.\n",
    "        \n",
    "        Args:\n",
    "            X (array-like) : feature vectors\n",
    "            y (array-like) : class labels\n",
    "            depth (int) : current depth of the tree\n",
    "        \"\"\"\n",
    "        if self.max_depth is not None and depth >= self.max_depth:\n",
    "            return DecisionNode(None, None, None, class_label=self._majority_class(y))\n",
    "    \n",
    "        \n",
    "    def feature_distance(self, xi, xj):\n",
    "        \"\"\"Calculate the distance between two feature vectors.\"\"\"\n",
    "        return np.sum(np.power(xi - xj, 2))\n",
    "    \n",
    "    def pignistic_probability_unit(self, A, B):\n",
    "        \"\"\"Calculate the pignistic probability of A given B.\n",
    "        \n",
    "        Args:\n",
    "            A (array-like) : subset of B\n",
    "            B (array-like) : evidence\n",
    "            m (array-like) : mass function of B\n",
    "        \"\"\"\n",
    "        if len(B) == 0:\n",
    "            return 0\n",
    "        return len(np.intersect1d(A, B)) / len(B)\n",
    "    \n",
    "    def cutting_points(self, feature):\n",
    "        \"\"\"Find all possible cutting points for a feature.\"\"\"\n",
    "        return np.unique(self.X[:, feature])\n",
    "    \n",
    "    def cut_feature(self, instance_indices, feature, cutting_point):\n",
    "        \"\"\"Split the dataset based on a feature and cutting point and return the indices of the points.\"\"\"\n",
    "        L = np.where(self.X[:, feature] < cutting_point)[0]\n",
    "        R = np.where(self.X[:, feature] > cutting_point)[0]\n",
    "        L = np.intersect1d(L, instance_indices)\n",
    "        R = np.intersect1d(R, instance_indices)\n",
    "        return L, R\n",
    "    \n",
    "    def calculate_centers(self, l, r, parent_mass):\n",
    "        \"\"\"Calculate the centers of the child nodes.\"\"\"\n",
    "        l_sum  = np.sum([parent_mass[i] for i in l])\n",
    "        if l_sum == 0:\n",
    "            c_l = np.zeros(self.X.shape[1], dtype=float)\n",
    "        else:\n",
    "            c_l = np.sum([self.X[i] * parent_mass[i] for i in l], axis=0) / l_sum\n",
    "            \n",
    "        r_sum = np.sum([parent_mass[i] for i in r])\n",
    "        if r_sum == 0:\n",
    "            c_r = np.zeros(self.X.shape[1], dtype=float)\n",
    "        else:\n",
    "            c_r = np.sum([self.X[i] * parent_mass[i] for i in r], axis=0) / r_sum\n",
    "        return c_l, c_r\n",
    "    \n",
    "    def calculate_mass_functions(self, instance_indices, cutting_point, c_l, c_r, gamma):\n",
    "        \"\"\"Calculate the mass function for the child nodes.\"\"\"\n",
    "        d_l = np.array([self.feature_distance(self.X[i], c_l) for i in instance_indices]) / self.feature_distance(c_l, cutting_point)\n",
    "        d_r = np.array([self.feature_distance(self.X[i], c_r) for i in instance_indices]) / self.feature_distance(c_r, cutting_point)\n",
    "        d_m = np.array([self.feature_distance(self.X[i], cutting_point) for i in instance_indices]) / (self.feature_distance(c_l, c_r) / gamma)\n",
    "        \n",
    "        inv_dl = np.array([1.0 / d if d != 0 else 0 for d in d_l])\n",
    "        inv_dr = np.array([1.0 / d if d != 0 else 0 for d in d_r])\n",
    "        inv_dm = np.array([1.0 / d if d != 0 else 0 for d in d_m])\n",
    "        \n",
    "        m_l = inv_dl / (inv_dl + inv_dr + inv_dm)\n",
    "        m_r = inv_dr / (inv_dl + inv_dr + inv_dm)\n",
    "        m_m = inv_dm / (inv_dl + inv_dr + inv_dm)\n",
    "        \n",
    "        return m_l, m_r, m_m\n",
    "    \n",
    "    def assign_clusters(self, instance_indices, m_l, m_r, m_m):\n",
    "        \"\"\"Assign instances to clusters based on the mass functions.\"\"\"\n",
    "        all_mass_functions = np.array([m_l, m_r, m_m])\n",
    "        cluster_assignments = np.argmax(all_mass_functions, axis=0)\n",
    "        # print(cluster_assignments)\n",
    "        # print(len(cluster_assignments))\n",
    "        clusters = [instance_indices[cluster_assignments == i] for i in range(3)]\n",
    "        l = clusters[0]\n",
    "        r = clusters[1]\n",
    "        m = clusters[2]\n",
    "        return l, r, m\n",
    "    \n",
    "    def calculate_silhouette(self, l, r, m, m_l, m_r, m_m, c_l, c_r, cutting_point):\n",
    "        pignistic_probability_l = self.pignistic_probability_unit(l, l) * m_l + self.pignistic_probability_unit(l, r) * m_r + self.pignistic_probability_unit(l, m) * m_m\n",
    "        pignistic_probability_r = self.pignistic_probability_unit(r, r) * m_r + self.pignistic_probability_unit(r, l) * m_l + self.pignistic_probability_unit(r, m) * m_m\n",
    "        pignistic_probability_m = self.pignistic_probability_unit(m, m) * m_m + self.pignistic_probability_unit(m, l) * m_m + self.pignistic_probability_unit(m, r) * m_r\n",
    "        \n",
    "        # print(\"Pignistic Probability L: \", pignistic_probability_l)\n",
    "        # print(\"Pignistic Probability R: \", pignistic_probability_r)\n",
    "        # print(\"Pignistic Probability M: \", pignistic_probability_m)\n",
    "                \n",
    "        a_l = np.array([np.sum([self.feature_distance(self.X[i], self.X[j]) * (pignistic_probability_l[j]) for j in l]) for i in l]) / (np.sum([pignistic_probability_l[j] for j in l]))\n",
    "        a_r = np.array([np.sum([self.feature_distance(self.X[i], self.X[j]) * (pignistic_probability_r[j]) for j in r]) for i in r]) / (np.sum([pignistic_probability_r[j] for j in r]))\n",
    "        a_m = np.array([np.sum([self.feature_distance(self.X[i], self.X[j]) * (pignistic_probability_m[j]) for j in m]) for i in m]) / (np.sum([pignistic_probability_m[j] for j in m]))\n",
    "        \n",
    "        # print(\"A_L: \", a_l)\n",
    "        # print(\"A_R: \", a_r)\n",
    "        # print(\"A_M: \", a_m)\n",
    "\n",
    "        clusters = [l, r, m]\n",
    "        pignistic_probabilities = [pignistic_probability_l, pignistic_probability_r, pignistic_probability_m]\n",
    "\n",
    "        n_l = 0\n",
    "        if self.feature_distance(c_l, c_r) > self.feature_distance(c_l, cutting_point):\n",
    "            n_l = 2\n",
    "        else:\n",
    "            n_l = 1\n",
    "\n",
    "        n_r = 0\n",
    "        if self.feature_distance(c_r, c_l) > self.feature_distance(c_r, cutting_point):\n",
    "            n_r = 2\n",
    "        else:\n",
    "            n_r = 0\n",
    "\n",
    "        n_m = 0\n",
    "        if self.feature_distance(cutting_point, c_l) > self.feature_distance(cutting_point, c_r):\n",
    "            n_m = 1\n",
    "        else:\n",
    "            n_m = 0\n",
    "\n",
    "        psum_l = np.sum([pignistic_probabilities[n_l][j] for j in clusters[n_l]])\n",
    "        psum_r = np.sum([pignistic_probabilities[n_r][j] for j in clusters[n_r]])\n",
    "        psum_m = np.sum([pignistic_probabilities[n_m][j] for j in clusters[n_m]])\n",
    "        \n",
    "        if psum_l == 0:\n",
    "            b_l = np.zeros(len(l))\n",
    "        else:\n",
    "            b_l = np.array([np.sum([self.feature_distance(self.X[i], self.X[j]) * (pignistic_probabilities[n_l][j]) for j in clusters[n_l]]) for i in l]) / psum_l\n",
    "            \n",
    "        if psum_r == 0:\n",
    "            b_r = np.zeros(len(r))\n",
    "        else:\n",
    "            b_r = np.array([np.sum([self.feature_distance(self.X[i], self.X[j]) * (pignistic_probabilities[n_r][j]) for j in clusters[n_r]]) for i in r]) / psum_r\n",
    "            \n",
    "        if psum_m == 0:\n",
    "            b_m = np.zeros(len(m))\n",
    "        else:\n",
    "            b_m = np.array([np.sum([self.feature_distance(self.X[i], self.X[j]) * (pignistic_probabilities[n_m][j]) for j in clusters[n_m]]) for i in m]) / psum_m\n",
    "        \n",
    "        # print(\"B_L: \", b_l)\n",
    "        # print(\"B_R: \", b_r)\n",
    "        # print(\"B_M: \", b_m)\n",
    "        \n",
    "        es_l = np.abs(b_l - a_l) / np.maximum(a_l, b_l)\n",
    "        es_r = np.abs(b_r - a_r) / np.maximum(a_r, b_r)\n",
    "        es_m = np.abs(b_m - a_m) / np.maximum(a_m, b_m)\n",
    "        \n",
    "        # print(\"ES_L: \", es_l)\n",
    "        # print(\"ES_R: \", es_r)\n",
    "        # print(\"ES_M: \", es_m)\n",
    "\n",
    "        max_pignistic_probability = np.maximum(pignistic_probability_l, pignistic_probability_r, pignistic_probability_m)\n",
    "        # print(\"Max Pignistic Probability: \", max_pignistic_probability)\n",
    "        \n",
    "        \n",
    "        num_sum = 0\n",
    "        den_sum = 0\n",
    "        for i in range(len(es_l)):\n",
    "            num_sum += max_pignistic_probability[l[i]] * es_l[i]\n",
    "            den_sum += max_pignistic_probability[l[i]]\n",
    "        for i in range(len(es_r)):\n",
    "            num_sum += max_pignistic_probability[r[i]] * es_r[i]\n",
    "            den_sum += max_pignistic_probability[r[i]]\n",
    "        for i in range(len(es_m)):\n",
    "            num_sum += max_pignistic_probability[m[i]] * es_m[i]\n",
    "            den_sum += max_pignistic_probability[m[i]]\n",
    "            \n",
    "        # print(\"Num Sum: \", num_sum)\n",
    "        # print(\"Den Sum: \", den_sum)\n",
    "        \n",
    "        if den_sum == 0:\n",
    "            average_silhouette = 0\n",
    "        else:\n",
    "            average_silhouette = num_sum / den_sum\n",
    "        \n",
    "        return average_silhouette      \n",
    "    \n",
    "    def max_silhouette(self, instance_indices, feature):\n",
    "        \"\"\"Find the cutting point with the largest average silhouette value.\"\"\"\n",
    "        cutting_points = self.cutting_points(feature)\n",
    "        max_silhouette = -np.inf\n",
    "        best_cutting_point = None\n",
    "        for cutting_point in cutting_points:\n",
    "            l, r = self.cut_feature(instance_indices, feature, cutting_point)\n",
    "            c_l, c_r = self.calculate_centers(l, r, np.ones(len(instance_indices), dtype=float))\n",
    "            # print(\"C_L: \", c_l[feature], \" C_R: \", c_r[feature])\n",
    "            m_l, m_r, m_m = self.calculate_mass_functions(instance_indices, cutting_point, c_l, c_r, gamma=1.0)\n",
    "            # print(\"M_L: \", m_l, \" M_R: \", m_r, \" M_M: \", m_m)            \n",
    "            l, r, m = self.assign_clusters(instance_indices, m_l, m_r, m_m)\n",
    "            silhouette = self.calculate_silhouette(l, r, m, m_l, m_r, m_m, c_l, c_r, cutting_point)\n",
    "            \n",
    "            print(\"Cutting Point: \", cutting_point, \"Average Silhouette: \", silhouette)\n",
    "            if silhouette > max_silhouette:\n",
    "                max_silhouette = silhouette\n",
    "                best_cutting_point = cutting_point\n",
    "        return best_cutting_point, max_silhouette"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cutting Point:  1.36 Average Silhouette:  0.6022057777120166\n",
      "Cutting Point:  1.7 Average Silhouette:  0.7445101479771361\n",
      "Cutting Point:  1.71 Average Silhouette:  0.7660891806246884\n",
      "Cutting Point:  1.75 Average Silhouette:  0.7515237493376903\n",
      "Cutting Point:  1.82 Average Silhouette:  0.763900837111101\n",
      "Cutting Point:  1.88 Average Silhouette:  0.7643232242286874\n",
      "Cutting Point:  1.9 Average Silhouette:  0.7619423780352905\n",
      "Cutting Point:  1.92 Average Silhouette:  0.7631092757468028\n",
      "Cutting Point:  1.94 Average Silhouette:  0.7631631587210344\n",
      "Cutting Point:  1.95 Average Silhouette:  0.7532842223982654\n",
      "Cutting Point:  1.98 Average Silhouette:  0.7641654959179881\n",
      "Cutting Point:  1.99 Average Silhouette:  0.7597642589437851\n",
      "Cutting Point:  2.0 Average Silhouette:  0.7604754209367144\n",
      "Cutting Point:  2.02 Average Silhouette:  0.7554798742767513\n",
      "Cutting Point:  2.04 Average Silhouette:  0.7535741733819752\n",
      "Cutting Point:  2.1 Average Silhouette:  0.7658222206823567\n",
      "Cutting Point:  2.12 Average Silhouette:  0.7745691703976013\n",
      "Cutting Point:  2.13 Average Silhouette:  0.7843386447058884\n",
      "Cutting Point:  2.14 Average Silhouette:  0.7779692406147206\n",
      "Cutting Point:  2.15 Average Silhouette:  0.7834669299068144\n",
      "Cutting Point: "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[82], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m tree \u001b[38;5;241m=\u001b[39m DecisonTree()\n\u001b[1;32m----> 2\u001b[0m \u001b[43mtree\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_silhouette\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtree\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mroot_instance_indices\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[80], line 259\u001b[0m, in \u001b[0;36mDecisonTree.max_silhouette\u001b[1;34m(self, instance_indices, feature)\u001b[0m\n\u001b[0;32m    256\u001b[0m l, r, m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39massign_clusters(instance_indices, m_l, m_r, m_m)\n\u001b[0;32m    257\u001b[0m silhouette \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcalculate_silhouette(l, r, m, m_l, m_r, m_m, c_l, c_r, cutting_point)\n\u001b[1;32m--> 259\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCutting Point: \u001b[39m\u001b[38;5;124m\"\u001b[39m, cutting_point, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAverage Silhouette: \u001b[39m\u001b[38;5;124m\"\u001b[39m, silhouette)\n\u001b[0;32m    260\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m silhouette \u001b[38;5;241m>\u001b[39m max_silhouette:\n\u001b[0;32m    261\u001b[0m     max_silhouette \u001b[38;5;241m=\u001b[39m silhouette\n",
      "File \u001b[1;32mc:\\Users\\vigna\\miniconda3\\Lib\\site-packages\\ipykernel\\iostream.py:694\u001b[0m, in \u001b[0;36mOutStream.write\u001b[1;34m(self, string)\u001b[0m\n\u001b[0;32m    692\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpub_thread\u001b[38;5;241m.\u001b[39mschedule(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flush)\n\u001b[0;32m    693\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 694\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_schedule_flush\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    696\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(string)\n",
      "File \u001b[1;32mc:\\Users\\vigna\\miniconda3\\Lib\\site-packages\\ipykernel\\iostream.py:590\u001b[0m, in \u001b[0;36mOutStream._schedule_flush\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    587\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_schedule_in_thread\u001b[39m():\n\u001b[0;32m    588\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_io_loop\u001b[38;5;241m.\u001b[39mcall_later(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mflush_interval, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flush)\n\u001b[1;32m--> 590\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpub_thread\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mschedule\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_schedule_in_thread\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\vigna\\miniconda3\\Lib\\site-packages\\ipykernel\\iostream.py:267\u001b[0m, in \u001b[0;36mIOPubThread.schedule\u001b[1;34m(self, f)\u001b[0m\n\u001b[0;32m    265\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_events\u001b[38;5;241m.\u001b[39mappend(f)\n\u001b[0;32m    266\u001b[0m     \u001b[38;5;66;03m# wake event thread (message content is ignored)\u001b[39;00m\n\u001b[1;32m--> 267\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_event_pipe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    268\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    269\u001b[0m     f()\n",
      "File \u001b[1;32mc:\\Users\\vigna\\miniconda3\\Lib\\site-packages\\zmq\\sugar\\socket.py:696\u001b[0m, in \u001b[0;36mSocket.send\u001b[1;34m(self, data, flags, copy, track, routing_id, group)\u001b[0m\n\u001b[0;32m    689\u001b[0m         data \u001b[38;5;241m=\u001b[39m zmq\u001b[38;5;241m.\u001b[39mFrame(\n\u001b[0;32m    690\u001b[0m             data,\n\u001b[0;32m    691\u001b[0m             track\u001b[38;5;241m=\u001b[39mtrack,\n\u001b[0;32m    692\u001b[0m             copy\u001b[38;5;241m=\u001b[39mcopy \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    693\u001b[0m             copy_threshold\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy_threshold,\n\u001b[0;32m    694\u001b[0m         )\n\u001b[0;32m    695\u001b[0m     data\u001b[38;5;241m.\u001b[39mgroup \u001b[38;5;241m=\u001b[39m group\n\u001b[1;32m--> 696\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mflags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrack\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrack\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mzmq/backend/cython/socket.pyx:742\u001b[0m, in \u001b[0;36mzmq.backend.cython.socket.Socket.send\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mzmq/backend/cython/socket.pyx:789\u001b[0m, in \u001b[0;36mzmq.backend.cython.socket.Socket.send\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mzmq/backend/cython/socket.pyx:250\u001b[0m, in \u001b[0;36mzmq.backend.cython.socket._send_copy\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\vigna\\miniconda3\\Lib\\site-packages\\zmq\\backend\\cython\\checkrc.pxd:13\u001b[0m, in \u001b[0;36mzmq.backend.cython.checkrc._check_rc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "tree = DecisonTree()\n",
    "tree.max_silhouette(tree.root_instance_indices, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.423e+01 1.710e+00 2.430e+00 ... 1.040e+00 3.920e+00 1.065e+03]\n",
      " [1.320e+01 1.780e+00 2.140e+00 ... 1.050e+00 3.400e+00 1.050e+03]\n",
      " [1.316e+01 2.360e+00 2.670e+00 ... 1.030e+00 3.170e+00 1.185e+03]\n",
      " ...\n",
      " [1.327e+01 4.280e+00 2.260e+00 ... 5.900e-01 1.560e+00 8.350e+02]\n",
      " [1.317e+01 2.590e+00 2.370e+00 ... 6.000e-01 1.620e+00 8.400e+02]\n",
      " [1.413e+01 4.100e+00 2.740e+00 ... 6.100e-01 1.600e+00 5.600e+02]]\n",
      "(178, 13)\n"
     ]
    }
   ],
   "source": [
    "Dataset = fetch_ucirepo(id=109)\n",
    "X = Dataset.data.features\n",
    "#convert X to a numpy array\n",
    "X = np.array(X)\n",
    "print(X)\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.unique(X[:, 0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.where(X[:, 0] < 15.67)[0])\n",
    "print(X[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
